# Robust Detectron2 Configuration for Instance Segmentation
# This configuration eliminates redundancies and provides clean, maintainable setup
# 
# OPTIMIZED CONFIGURATION - Trial 8 from Optuna Bayesian Optimization
# Best AP75: 78.217822 achieved with hyperparameter optimization
# Optimization completed: Sun Aug 3 12:12:20 PM EDT 2025

# =============================================================================
# CORE MODEL CONFIGURATION
# =============================================================================

# Output directory for checkpoints and logs
output_dir: "checkpoints/detectron2_pointrend/leaf_pointrend_8-1"

# Model architecture configuration
model:
  # Backbone architecture: "resnet50" or "resnext101"
  backbone: "resnext101"
  
  # PointRend configuration for enhanced mask boundaries
  pointrend:
    enabled: true  # ENABLED for enhanced boundary refinement
    # Features to use for point-based refinement
    in_features: ["p2", "p3", "p4", "p5"]
    # Number of convolution layers in point head
    num_conv: 3
    # Convolution dimension
    conv_dim: 256
    # Number of points for coarse prediction (14x14 = 196)
    num_points: 196
    # Oversampling ratio for point selection
    oversample_ratio: 3
    # Importance sampling ratio (optimized by Optuna trial 8)
    importance_sample_ratio: 0.7322442574508008
    # Number of subdivision steps for refinement (optimized by Optuna trial 8)
    subdivision_steps: 3
    # Number of points for fine prediction (optimized by Optuna trial 8)
    subdivision_num_points: 660

  # Custom anchor configuration optimized for peduncle dataset
  anchor_generator:
    # Anchor sizes based on dataset analysis
    sizes: [[257], [1139], [2056], [3183], [4475]]
    # Aspect ratios optimized for leaf sizes
    aspect_ratios: [[0.76, 0.85, 0.94, 1.01, 1.13]]

  # Feature Pyramid Network enhancements
  fpn:
    # Fusion method: "sum" (default) or "avg"
    fuse_type: "avg"
    # Normalization: "" (none), "GN" (GroupNorm), "BN" (BatchNorm)
    norm: "GN"

  # ResNet deformable convolutions for better non-rigid object handling
  resnets:
    # Enable deformable convolutions on deeper stages
    deform_on_per_stage: [false, false, true, true]

# =============================================================================
# DATASET CONFIGURATION
# =============================================================================

datasets:
  # Training annotations
  train_json: "data/annotations/coco/train/_annotations.coco.json"
  # Validation annotations  
  val_json: "data/annotations/coco/valid/_annotations.coco.json"
  # Image directories to search (supports multiple paths for flexibility)
  image_dirs:
    - "data/annotations/coco/train"
    - "data/annotations/coco/valid"

# =============================================================================
# DATA LOADING CONFIGURATION
# =============================================================================

dataloader:
  # Number of data loading workers
  num_workers: 32

# Input preprocessing configuration
INPUT:
  # Multi-scale training sizes for better generalization
  MIN_SIZE_TRAIN: [800, 1024, 1280]
  MAX_SIZE_TRAIN: 1600
  # Test-time input sizes
  MIN_SIZE_TEST: [1600]
  MAX_SIZE_TEST: 1600
  # Mask format: 'bitmask' for PointRend, 'polygon' for standard Mask R-CNN
  # (Automatically set based on PointRend enablement in training script)
  # MASK_FORMAT: "bitmask"  # Uncomment to force bitmask format

# Data augmentation configuration (optimized by Optuna trial 8)
augmentation:
  # Horizontal flip probability
  horizontal_flip_prob: 0.6485842360750871
  # Vertical flip probability  
  vertical_flip_prob: 0.4214688307596458

# =============================================================================
# TRAINING CONFIGURATION
# =============================================================================

solver:
  # Images per batch (adjust based on GPU memory)
  ims_per_batch: 5
  # Base learning rate (optimized by Optuna trial 8)
  base_lr: 0.0003518920565826005
  # Weight decay (optimized by Optuna trial 8)
  weight_decay: 0.0007234279845665417
  # Warmup iterations for stable training start (optimized by Optuna trial 8)
  warmup_iters: 1712
  # Warmup factor
  warmup_factor: 0.0001
  # Total training iterations (generous buffer beyond observed peak at 5250)
  max_iter: 7000
  # Learning rate decay steps (optimized by Optuna trial 8: 0.6900211269531271 * 7000 = 4830)
  steps: [4830]
  # Checkpoint saving frequency
  checkpoint_period: 500
# =============================================================================
# EARLY STOPPING CONFIGURATION
# =============================================================================

early_stopping:
  # Enable early stopping to prevent overfitting
  enabled: true
  
  # Primary metric to monitor for early stopping
  # Options: "segm/AP", "segm/AP50", "segm/AP75", "bbox/AP", "loss_total"
  metric: "segm/AP75"
  
  # Moderately aggressive patience to catch peak performance while allowing for brief plateaus
  patience: 3
  
  # Minimum improvement threshold to reset patience counter
  # Small positive value prevents stopping due to minor fluctuations
  min_delta: 0.001
  
  # Direction of improvement: "max" for metrics like AP, "min" for losses
  mode: "max"
  
  # More frequent validation for faster early stopping detection
  eval_period: 150
  
  # Minimum iterations before early stopping can trigger (aligned with 7000 iter schedule)
  min_iterations: 2000
  
  # Optional: restore best weights when early stopping triggers
  restore_best_weights: true
  
  # Optional: save best model separately
  save_best_model: true
  best_model_filename: "model_best.pth"

# =============================================================================
# MODEL HEAD CONFIGURATION
# =============================================================================

roi_heads:
  # Number of object classes (1 for peduncle detection)
  num_classes: 1
  # ROI batch size per image (optimized by Optuna trial 8)
  batch_size_per_image: 143
  # Positive fraction for ROI sampling (optimized by Optuna trial 8)
  positive_fraction: 0.43888778463576217
  # Test-time score threshold (optimized by Optuna trial 8)
  SCORE_THRESH_TEST: 0.6843197248237434
  # Non-maximum suppression threshold
  NMS_THRESH_TEST: 0.5
  # Maximum detections per image
  DETECTIONS_PER_IMAGE: 3

# Mask head configuration for precise segmentation
mask_head:
  # Number of convolution layers
  NUM_CONV: 4
  # Pooler resolution - MUST be 14 to match PointRend pretrained weights
  POOLER_RESOLUTION: 14
  # Pooler sampling ratio
  POOLER_SAMPLING_RATIO: 2
  # Mask loss weight (emphasize mask quality)
  LOSS_WEIGHT: 2.0

# =============================================================================
# TEST-TIME CONFIGURATION
# =============================================================================

TEST:
  # Test-time augmentation for improved accuracy
  AUG:
    ENABLED: true
    MIN_SIZES: [800, 1024, 1280, 1600]
    MAX_SIZE: 1600
    FLIP: true

# =============================================================================
# LOGGING AND MONITORING
# =============================================================================

logging:
  # Enable intelligent GPU utilization monitoring during training
  gpu_monitoring: true
  # Monitoring interval in seconds (minimum 10s, recommended 30-60s)
  monitor_interval_sec: 30
  
  # Enhanced logging for early stopping
  early_stopping_verbose: true
  # Log early stopping metrics every N evaluations
  early_stopping_log_frequency: 1

# =============================================================================
# CONFIGURATION NOTES
# =============================================================================
#
# Early Stopping Implementation Notes:
# 
# 1. Metric Selection:
#    - "segm/AP" (recommended): Overall segmentation average precision
#    - "segm/AP50": AP at IoU threshold 0.5 (less strict, may stop earlier)
#    - "segm/AP75": AP at IoU threshold 0.75 (more strict, better quality)
#    - "bbox/AP": Bounding box AP (less relevant for segmentation quality)
#
# 2. Patience Configuration:
#    - patience=4 with eval_period=500 means 2000 iterations without improvement
#    - Adjust based on your dataset size and training dynamics
#    - Larger datasets may need higher patience (5-8)
#    - Smaller datasets may need lower patience (2-3)
#
# 3. min_delta Tuning:
#    - 0.001 is good for AP metrics (0.1% improvement threshold)
#    - Use 0.0001 for very precise stopping
#    - Use 0.01 for less sensitive stopping
#
# 4. Performance Considerations:
#    - eval_period=500 balances monitoring overhead with responsiveness
#    - Set to checkpoint_period for efficiency (reuses evaluation)
#    - Lower values (250-300) for more responsive stopping
#    - Higher values (1000) for less overhead but slower response
#
# 5. Safety Mechanisms:
#    - min_iterations=2000 prevents stopping during initial unstable phase
#    - restore_best_weights=true ensures best model is preserved
#    - save_best_model=true creates separate file for best checkpoint
#
# 6. Integration with Existing Training:
#    - Works with existing checkpoint_period and solver configuration
#    - Compatible with PointRend and all other model configurations
#    - Evaluation metrics computed using existing COCOEvaluator
#    - Early stopping hook integrates cleanly with Detectron2 training loop
#
# Recommended Starting Configuration:
# - Start with default values above for most segmentation tasks
# - Monitor training logs to see evaluation frequency and metric trends
# - Adjust patience based on your dataset size and training stability
# - Use segm/AP for general purpose, segm/AP75 for high-quality requirements

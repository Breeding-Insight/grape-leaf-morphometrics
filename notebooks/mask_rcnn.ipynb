{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a mask-rcnn model for leaf morphometrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os and set environment variables\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "# Import standard libraries\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import traceback\n",
    "\n",
    "# Import third-party libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "# Import specific modules from torchvision\n",
    "import torch.multiprocessing as mp\n",
    "mp.set_start_method('spawn', force=True)\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:44:07) [Clang 18.1.8 ]\n",
      "Torch version: 2.7.0.dev20250305\n",
      "Torchvision version: 0.22.0.dev20250305\n"
     ]
    }
   ],
   "source": [
    "# Check Python version\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Check Torch version\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "\n",
    "# Check Torchvision version\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish LeafDataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeafDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, annotations_file, transforms):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.coco = torchvision.datasets.CocoDetection(root, annotations_file)\n",
    "        self.ids = list(sorted(self.coco.ids))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.ids[index]\n",
    "        img, target = self.coco[index]\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        masks = []\n",
    "        area = []\n",
    "        iscrowd = []\n",
    "\n",
    "        for annotation in target:\n",
    "            bbox = annotation['bbox']\n",
    "            x1, y1, width, height = bbox\n",
    "            x2 = x1 + width\n",
    "            y2 = y1 + height\n",
    "            boxes.append([x1, y1, x2, y2])\n",
    "\n",
    "            category_id = annotation['category_id']\n",
    "            labels.append(category_id)\n",
    "\n",
    "            if 'segmentation' in annotation:\n",
    "                mask = self.coco.coco.annToMask(annotation)\n",
    "                masks.append(mask)\n",
    "\n",
    "            if 'area' in annotation:\n",
    "                area.append(annotation['area'])\n",
    "            else:\n",
    "                area.append(width * height)\n",
    "\n",
    "            if 'iscrowd' in annotation:\n",
    "                iscrowd.append(annotation['iscrowd'])\n",
    "            else:\n",
    "                iscrowd.append(0)\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        if masks:\n",
    "            masks = np.stack(masks)\n",
    "            masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "        else:\n",
    "            masks = torch.zeros((0, img.height, img.width), dtype=torch.uint8)\n",
    "\n",
    "        area = torch.as_tensor(area, dtype=torch.float32)\n",
    "        iscrowd = torch.as_tensor(iscrowd, dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        target['masks'] = masks\n",
    "        target['image_id'] = torch.tensor([img_id])\n",
    "        target['area'] = area\n",
    "        target['iscrowd'] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define top level functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define instance segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance_segmentation_model(num_classes):\n",
    "    weights = torchvision.models.detection.MaskRCNN_ResNet50_FPN_Weights.DEFAULT\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=weights)\n",
    "\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the transform function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, device, log_message=print):\n",
    "    \"\"\"\n",
    "    Evaluate the model on a dataset without computing gradients.\n",
    "    Returns the average loss.\n",
    "    \"\"\"\n",
    "    model.train()  # Temporarily set to train mode to compute losses\n",
    "    total_loss = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    try:\n",
    "        with torch.no_grad():  # No gradients needed for evaluation\n",
    "            for i, (images, targets) in enumerate(data_loader):\n",
    "                images = list(image.to(device) for image in images)\n",
    "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "                # Forward pass and compute loss\n",
    "                loss_dict = model(images, targets)\n",
    "\n",
    "                # Sum all losses\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "                total_loss += losses.item()\n",
    "                batch_count += 1\n",
    "\n",
    "                if (i + 1) % 5 == 0:  # Log progress\n",
    "                    log_message(f\"  Eval batch {i+1}/{len(data_loader)}, Loss: {losses.item():.4f}\")\n",
    "\n",
    "                # Clear memory\n",
    "                del images, targets, loss_dict, losses\n",
    "                gc.collect()\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "        model.eval()  # Set back to eval mode\n",
    "        avg_loss = total_loss / batch_count if batch_count > 0 else 0\n",
    "        return avg_loss\n",
    "    except Exception as e:\n",
    "        model.eval()  # Ensure model is set back to eval mode even if an error occurs\n",
    "        log_message(f\"Error during evaluation: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return float('inf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your annotated images and annotations\n",
    "data_path = \"/Users/aja294/Documents/Grape_local/projects/leaf_morphometrics/data/annotations\"\n",
    "checkpoint_path = \"/Users/aja294/Documents/Grape_local/projects/leaf_morphometrics/models/mask_rcnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories for train, validation, and test\n",
    "train_dir = os.path.join(data_path, \"coco\", \"train\")\n",
    "val_dir = os.path.join(data_path, \"coco\", \"valid\")\n",
    "test_dir = os.path.join(data_path, \"coco\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define annotation files\n",
    "train_annotations_file = os.path.join(train_dir, \"_annotations.coco.json\")\n",
    "val_annotations_file = os.path.join(val_dir, \"_annotations.coco.json\")\n",
    "test_annotations_file = os.path.join(test_dir, \"_annotations.coco.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path: /Users/aja294/Documents/Grape_local/projects/leaf_morphometrics/data/annotations\n",
      "Train path: /Users/aja294/Documents/Grape_local/projects/leaf_morphometrics/data/annotations/coco/train\n",
      "Validation path: /Users/aja294/Documents/Grape_local/projects/leaf_morphometrics/data/annotations/coco/valid\n",
      "Test path: /Users/aja294/Documents/Grape_local/projects/leaf_morphometrics/data/annotations/coco/test\n"
     ]
    }
   ],
   "source": [
    " # Create directories if they don't exist\n",
    "for directory in [train_dir, val_dir, test_dir]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "print(f\"Data path: {data_path}\")\n",
    "print(f\"Train path: {train_dir}\")\n",
    "print(f\"Validation path: {val_dir}\")\n",
    "print(f\"Test path: {test_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if annotation files exist\n",
    "missing_files = []\n",
    "for file_path, name in [(train_annotations_file, \"Training\"), \n",
    "                        (val_annotations_file, \"Validation\"), \n",
    "                        (test_annotations_file, \"Testing\")]:\n",
    "    if not os.path.exists(file_path):\n",
    "        missing_files.append((name, file_path))\n",
    "\n",
    "if missing_files:\n",
    "    for name, path in missing_files:\n",
    "        print(f\"Warning: {name} annotations file not found at {path}\")\n",
    "    print(\"Please ensure all annotation files exist before proceeding.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint directory: /Users/aja294/Documents/Grape_local/projects/leaf_morphometrics/models/mask_rcnn/checkpoints_20250305_165324\n"
     ]
    }
   ],
   "source": [
    "# Create checkpoint directory with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "checkpoint_dir = os.path.join(checkpoint_path, f\"checkpoints_{timestamp}\")\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "print(f\"Checkpoint directory: {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training started at 20250305_165324 ===\n",
      "Loading datasets...\n"
     ]
    }
   ],
   "source": [
    "# Create log file\n",
    "log_file = os.path.join(checkpoint_dir, \"training_log.txt\")\n",
    "\n",
    "def log_message(message):\n",
    "    \"\"\"Write message to log file and print to console\"\"\"\n",
    "    print(message)\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(f\"{message}\\n\")\n",
    "\n",
    "log_message(f\"=== Training started at {timestamp} ===\")\n",
    "\n",
    "# Load the datasets\n",
    "log_message(\"Loading datasets...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Training dataset loaded with 35 images\n"
     ]
    }
   ],
   "source": [
    "# Training dataset\n",
    "train_dataset = LeafDataset(train_dir, train_annotations_file, get_transform(train=True))\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=8, shuffle=True, num_workers=0, collate_fn=collate_fn\n",
    ")\n",
    "log_message(f\"Training dataset loaded with {len(train_dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Training dataset loaded with 35 images\n"
     ]
    }
   ],
   "source": [
    "# Training dataset V2\n",
    "train_dataset = LeafDataset(train_dir, train_annotations_file, get_transform(train=True))\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=16,           # Increased from 8 for better MPS utilization\n",
    "    shuffle=True,\n",
    "    num_workers=4,           # Increased from 0 to improve data loading speed\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,         # Added to speed up data transfer to MPS\n",
    "    persistent_workers=True  # Added to maintain workers between epochs\n",
    ")\n",
    "log_message(f\"Training dataset loaded with {len(train_dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Validation dataset loaded with 10 images\n"
     ]
    }
   ],
   "source": [
    "# Validation dataset\n",
    "val_dataset = None\n",
    "val_loader = None\n",
    "if os.path.exists(val_annotations_file):\n",
    "    val_dataset = LeafDataset(val_dir, val_annotations_file, get_transform(train=False))\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=8, shuffle=False, num_workers=0, collate_fn=collate_fn\n",
    "    )\n",
    "    log_message(f\"Validation dataset loaded with {len(val_dataset)} images\")\n",
    "else:\n",
    "    log_message(\"Validation dataset not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Test dataset loaded with 5 images\n"
     ]
    }
   ],
   "source": [
    "# Test dataset\n",
    "test_dataset = None\n",
    "test_loader = None\n",
    "if os.path.exists(test_annotations_file):\n",
    "    test_dataset = LeafDataset(test_dir, test_annotations_file, get_transform(train=False))\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=2, shuffle=False, num_workers=0, collate_fn=collate_fn\n",
    "    )\n",
    "    log_message(f\"Test dataset loaded with {len(test_dataset)} images\")\n",
    "else:\n",
    "    log_message(\"Test dataset not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Force run on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device forced to: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "log_message(f\"Device forced to: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Set up device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "log_message(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 3\n"
     ]
    }
   ],
   "source": [
    "# Get number of classes from training dataset\n",
    "num_classes = len(train_dataset.coco.coco.getCatIds()) + 1  # +1 for background\n",
    "log_message(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n",
      "Model initialized and moved to device\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "log_message(\"Initializing model...\")\n",
    "model = get_instance_segmentation_model(num_classes)\n",
    "model.to(device)\n",
    "log_message(\"Model initialized and moved to device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are existing checkpoints to resume from\n",
    "start_epoch = 0\n",
    "best_val_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for existing checkpoints in data_path/checkpoints\n",
    "base_checkpoint_dir = os.path.join(data_path, \"checkpoints\")\n",
    "if os.path.exists(base_checkpoint_dir):\n",
    "    checkpoint_dirs = [d for d in os.listdir(base_checkpoint_dir) \n",
    "                        if os.path.isdir(os.path.join(base_checkpoint_dir, d))]\n",
    "\n",
    "    if checkpoint_dirs:\n",
    "        # Find the latest checkpoint directory\n",
    "        latest_dir = max(checkpoint_dirs)\n",
    "        latest_checkpoint_dir = os.path.join(base_checkpoint_dir, latest_dir)\n",
    "\n",
    "        # Find the latest checkpoint file\n",
    "        checkpoints = [f for f in os.listdir(latest_checkpoint_dir) \n",
    "                        if f.endswith('.pth') and f.startswith('mask_rcnn_checkpoint_epoch_')]\n",
    "\n",
    "        if checkpoints:\n",
    "            latest_checkpoint = max(checkpoints, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "            checkpoint_path = os.path.join(latest_checkpoint_dir, latest_checkpoint)\n",
    "            log_message(f\"Loading checkpoint from {checkpoint_path}\")\n",
    "\n",
    "            try:\n",
    "                checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "                model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                start_epoch = checkpoint['epoch']\n",
    "                best_val_loss = checkpoint.get('best_val_loss', float('inf'))\n",
    "                log_message(f\"Resuming from epoch {start_epoch}\")\n",
    "            except Exception as e:\n",
    "                log_message(f\"Error loading checkpoint: {e}\")\n",
    "                log_message(\"Starting training from scratch\")\n",
    "                start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up optimizer and learning rate scheduler\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer and learning rate scheduler initialized\n"
     ]
    }
   ],
   "source": [
    "# Load optimizer and scheduler states if resuming\n",
    "if start_epoch > 0:\n",
    "    try:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        lr_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        log_message(\"Loaded optimizer and scheduler states\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error loading optimizer/scheduler states: {e}\")\n",
    "\n",
    "log_message(\"Optimizer and learning rate scheduler initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Starting training for 1 epochs\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/aja294/miniforge3/envs/pytorch_nightly-env/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/aja294/miniforge3/envs/pytorch_nightly-env/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/aja294/miniforge3/envs/pytorch_nightly-env/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "  File \"/Users/aja294/miniforge3/envs/pytorch_nightly-env/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "             ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^AttributeError^: ^Can't get attribute 'LeafDataset' on <module '__main__' (built-in)>^^\n",
      "AttributeError\n",
      ": Can't get attribute 'LeafDataset' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/aja294/miniforge3/envs/pytorch_nightly-env/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aja294/miniforge3/envs/pytorch_nightly-env/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'LeafDataset' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/aja294/miniforge3/envs/pytorch_nightly-env/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aja294/miniforge3/envs/pytorch_nightly-env/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'LeafDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 41099) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_nightly-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1283\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1282\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1283\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1284\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_nightly-env/lib/python3.11/multiprocessing/queues.py:113\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    112\u001b[39m timeout = deadline - time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_nightly-env/lib/python3.11/multiprocessing/connection.py:257\u001b[39m, in \u001b[36m_ConnectionBase.poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_nightly-env/lib/python3.11/multiprocessing/connection.py:440\u001b[39m, in \u001b[36mConnection._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m     r = \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_nightly-env/lib/python3.11/multiprocessing/connection.py:948\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m    947\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m948\u001b[39m     ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    949\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_nightly-env/lib/python3.11/selectors.py:415\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_nightly-env/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py:73\u001b[39m, in \u001b[36m_set_SIGCHLD_handler.<locals>.handler\u001b[39m\u001b[34m(signum, frame)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhandler\u001b[39m(signum, frame):\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[32m     72\u001b[39m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mRuntimeError\u001b[39m: DataLoader worker (pid 41099) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[111]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m log_message(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_nightly-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_nightly-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1490\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1487\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1489\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1490\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1491\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1493\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_nightly-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1452\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1448\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1449\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1450\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1451\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1452\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1453\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1454\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_nightly-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1296\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) > \u001b[32m0\u001b[39m:\n\u001b[32m   1295\u001b[39m     pids_str = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mstr\u001b[39m(w.pid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[32m-> \u001b[39m\u001b[32m1296\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1297\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) exited unexpectedly\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1298\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1299\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue.Empty):\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: DataLoader worker (pid(s) 41099) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "num_epochs = 1\n",
    "# Print the device\n",
    "print(f\"Device: {device}\")\n",
    "log_message(f\"Starting training for {num_epochs} epochs\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    log_message(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    # Training phase\n",
    "    for i, (images, targets) in enumerate(train_loader):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += losses.item()\n",
    "        batch_count += 1\n",
    "\n",
    "        if (i + 1) % 10 == 0:  # Print every 10 batches\n",
    "            log_message(f\"  Batch {i+1}/{len(train_loader)}, Loss: {losses.item():.4f}\")\n",
    "\n",
    "    # Print epoch training summary\n",
    "    avg_train_loss = epoch_loss / batch_count if batch_count > 0 else 0\n",
    "    log_message(f\"  Epoch {epoch+1} training completed. Average Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    # Validation phase\n",
    "    val_loss = None\n",
    "    if val_loader:\n",
    "        val_loss = evaluate_model(model, val_loader, device, log_message)\n",
    "        log_message(f\"  Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Update learning rate\n",
    "    lr_scheduler.step()\n",
    "    log_message(f\"  Learning rate updated to: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "    # Save checkpoint every epoch\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "        'train_loss': avg_train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'num_classes': num_classes\n",
    "    }\n",
    "\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'mask_rcnn_checkpoint_epoch_{epoch+1}.pth')\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    log_message(f\"  Checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "    # Save best model based on validation loss\n",
    "    if val_loss is not None and (epoch == start_epoch or val_loss < best_val_loss):\n",
    "        best_val_loss = val_loss\n",
    "        best_model_path = os.path.join(checkpoint_dir, 'mask_rcnn_best_model.pth')\n",
    "        torch.save(checkpoint, best_model_path)\n",
    "        log_message(f\"  New best model saved to {best_model_path} (val_loss: {best_val_loss:.4f})\")\n",
    "\n",
    "    # Calculate epoch duration\n",
    "    epoch_duration = time.time() - epoch_start_time\n",
    "    log_message(f\"  Epoch duration: {epoch_duration:.2f} seconds\")\n",
    "\n",
    "log_message(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "Test Loss: 0.7329\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set if available\n",
    "if test_loader:\n",
    "    log_message(\"Evaluating on test set...\")\n",
    "    test_loss = evaluate_model(model, test_loader, device)\n",
    "    log_message(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved to /Users/aja294/Documents/Grape_local/projects/leaf_morphometrics/models/mask_rcnn/checkpoints_20250305_135524/maskrcnn_model_final.pth\n"
     ]
    }
   ],
   "source": [
    "  # Save the final model\n",
    "final_model_path = os.path.join(checkpoint_dir, \"maskrcnn_model_final.pth\")\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'num_classes': num_classes,\n",
    "    'train_loss': avg_train_loss,\n",
    "    'val_loss': val_loss if val_loader else None,\n",
    "    'test_loss': test_loss if test_loader else None\n",
    "}, final_model_path)\n",
    "log_message(f\"Final model saved to {final_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created symlink to latest checkpoint directory: /Users/aja294/Documents/Grape_local/projects/leaf_morphometrics/models/mask_rcnn/latest\n"
     ]
    }
   ],
   "source": [
    "# Create a symlink to the latest checkpoint directory\n",
    "# Extract the base directory (without the checkpoints_timestamp part)\n",
    "base_dir = os.path.dirname(checkpoint_dir)\n",
    "latest_link = os.path.join(base_dir, \"latest\")\n",
    "\n",
    "# Check if the symlink already exists and remove it\n",
    "if os.path.exists(latest_link):\n",
    "    try:\n",
    "        os.remove(latest_link)\n",
    "    except:\n",
    "        # On some systems, we might need to use unlink for symlinks\n",
    "        os.unlink(latest_link)\n",
    "\n",
    "# Create the symlink pointing to the current checkpoint directory\n",
    "try:\n",
    "    os.symlink(checkpoint_dir, latest_link)\n",
    "    log_message(f\"Created symlink to latest checkpoint directory: {latest_link}\")\n",
    "except Exception as e:\n",
    "    log_message(f\"Error creating symlink: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_nightly-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
